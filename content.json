[{"title":"DSST折腾笔记（二）：在安卓手机下的移植","date":"2017-04-02T14:10:13.000Z","path":"2017/04/02/DSST折腾笔记（二）：在安卓手机下的移植/","text":"NDK环境配置好的基础上移植DSST到安卓所需的改动并不多，主要还是编译的配置。 博文结构： [TOC] 移植环境 android studio 2.2.3 opencv4android 3.2.0 测试机：荣耀7(arm64-v8a)、台电X98 Air III(x86) 前提条件顺利运行需要目标机器cpu架构是x86或x86_64的(直接使用SSE)或者arm64-v8a（原因上篇博文说过的）。自己的渣机还是armeabi-v7a的，跑不了，在室友清明去浪的前夜赶紧测试了一下他的手机和平板，正是我想要的！果断扣下平板留着后面测试啊哈哈！啥？白天出去浪晚上回旅馆要拿平板看电影？诶诶诶，一堆人晚上玩点别的多好，狼人杀啥的，还一个人看电影？室友对曰：一堆人看电影最好~我：……我：要看你就还是拿手机看吧2333~ 查看自己手机或平板的cpu架构方法：12adb shell cat /proc/cpuinfo 如图为室友平板的信息，对于flag一栏，需有sse。ARM架构的长这样（Features这一栏需有neon,当然这还不够，ARMv7还是32位机器，这个工程需要64位机器才能正常运行）： 移植过程及所遇问题首先在/app/src/main下新建一个include文件夹用于保存c头文件，将DSST的那几个头文件拷贝进来，而cpp文件则和native-lib.cpp放一块，即/app/src/main/cpp。然后在CMakeLists里加入头文件路径，并把其余cpp文件也编译添加到native-lib中来:12345include_directories(src/main/include)add_library( native-lib SHARED src/main/cpp/native-lib.cpp src/main/cpp/fdssttracker.cpp src/main/cpp/fhog.cpp) 如图：然后同样的，如果目标机器是arm架构，sse.hpp里需做相应头文件的调整，编译，得到熟悉的报错：1error: &quot;NEON support not enabled&quot; 解决方案：在app下的build.gradle的externalNativeBuild{cmake{}}下加入如下代码（注意大括号的包含关系）：1arguments &quot;-DANDROID_ARM_NEON=TRUE&quot;, &quot;-DANDROID_TOOLCHAIN=clang&quot; 编译，搞定，移植工作就算完成了。java层实现一下CameraBridgeViewBase.CvCameraViewListener2这个接口。控制逻辑上，在用户框选了跟踪目标后，将目标框和此帧画面喂给native层对tracker进行初始化，随后的每一帧都喂给native层另一个函数对tracker进行更新并返回新的目标位置给java层更新。 调试补充平时调试C/C++程序一般习惯用printf来掌握程序走向，判断可能的逻辑错误，NDK下自然也有这个需求。找到一种方法可以像java层使用Log类在logcat里打印消息：首先是编译配置，在app下的build.gradle的android{defaultConfig{ndk{}}}下加入ldLibs “log”（加完如下，注意大括号的包含关系）：1234ndk&#123; ldLibs &quot;log&quot; abiFilters &apos;armeabi-v7a&apos;&#125; 此外在CMakeLists中也要添加对log库的链接，如图：在代码中使用如下：123456789#include&quot;android/log.h&quot;//打印一个简单Info级别的日志 对应Java的Log.i(&quot;JNI&quot;,&quot;This is log&quot;)__android_log_print(ANDROID_LOG_INFO,&quot;JNI&quot;,&quot;This is log&quot;); //打印格式化字符串 这里使用的是C语言中printf中的格式。关于C中的printf格式化输出可自行百度，文档非常多。int i=5;__android_log_print(ANDROID_LOG_INFO,&quot;JNI&quot;,&quot;i=%d&quot;,i); 利用参考资料4提供的更优雅地使用方式是新建一个头文件，拷贝以下代码：123456789101112131415161718192021222324252627282930313233343536373839404142434445#include &quot;android/log.h&quot;#ifndef LOG_TAG #define LOG_TAG &quot;JNI&quot;#endif#ifndef IS_DEBUG #define IS_DEBUG true#endif#define LOG_NOOP (void) 0//__FILE__ 输出文件名//__LINE__ 输出行数//__PRETTY_FUNCTION__ 输出方法名//可以按需选取 %s %u %s 分别与之对应#define LOG_PRINT(level,fmt,...) __android_log_print(level,LOG_TAG,&quot;(%s:%u) %s: &quot; fmt,__FILE__,__LINE__,__PRETTY_FUNCTION__,##__VA_ARGS__)//通过IS_DEBUG来控制是否输出日志#if IS_DEBUG #define LOGI(fmt,...) LOG_PRINT(ANDROID_LOG_INFO,fmt,##__VA_ARGS__)#else #define LOGI(...) LOG_NOOP#endif#if IS_DEBUG #define LOGW(fmt,...) LOG_PRINT(ANDROID_LOG_WARN,fmt ,##__VA_ARGS__)#else #define LOGW(...) LOG_NOOP#endif#if IS_DEBUG #define LOGD(fmt,...) LOG_PRINT(ANDROID_LOG_DEBUG,fmt ,##__VA_ARGS__)#else #define LOGD(...) LOG_NOOP#endif#if IS_DEBUG #define LOGE(fmt,...) LOG_PRINT(ANDROID_LOG_ERROR,fmt ,##__VA_ARGS__)#else #define LOGE(...) LOG_NOOP#endif#if IS_DEBUG #define LOGF(fmt,...) LOG_PRINT(ANDROID_LOG_FATAL,fmt ,##__VA_ARGS__)#else #define LOGF(...) LOG_NOOP#endif 然后在需要使用的cpp文件中include即可1234567#include&quot;LogUtils.h&quot;int func(int i) &#123; LOGW(&quot;this is a warning&quot;); LOGE(&quot;i = %d&quot;,i); &#125; 跟踪效果以下是用室友的荣耀8跟踪鹅厂公仔的效果录屏： 参考资料 CMake | Android Developers-Using CMake variables in Gradle 向您的项目添加 C 和 C++ 代码 NDK Programmer’s Guide Android Studio NDK 入门教程（4）–优雅的在C++中输出Logcat java - ROI in OpenCV from Android - Stack Overflow","tags":[{"name":"opencv4android","slug":"opencv4android","permalink":"http://sheng-blog.iego.cn/tags/opencv4android/"},{"name":"tracking","slug":"tracking","permalink":"http://sheng-blog.iego.cn/tags/tracking/"}]},{"title":"DSST折腾笔记（一）：树莓派3上的移植","date":"2017-04-02T02:10:13.000Z","path":"2017/04/02/DSST折腾笔记（一）：树莓派3上的移植/","text":"DSST（文章全名Accurate Scale Estimation for Robust Visual Tracking）是视觉目标跟踪VOT2014竞赛的冠军。实测实时性好，跟踪效果着实很赞(当然就跟踪效果而言还是逊色于TLD，在一次测试里，我起身把待洗衣服拿去洗衣房，然后回来，TLD还是准确地重新把我的脸给找了出来，继续追踪！这个过程少说也有四五分钟，这么长时间的目标丢失，TLD居然没挂！TLD已是2009年的工作了，算是比较久远的了，却能火到现在，可见其地位)。回到DSST，这篇算法是基于MOSSE的改进，突出内容是加入了尺度变换，文中指出该算法亮点是大部分算法只要是多尺度问题，都可以通过DSST中的尺度部分来解决。2015年开始tracking就被深度学习的算法攻陷了，效果确实很赞，然而受硬件限制，也受速度限制，不适合在移动端跑。所以当前来说DSST应是最契合我的需求的了。先把它移植过来用着，后面再好好研究下代码，希望把深度信息利用进去进一步提升工程上的跟踪效果。 博文结构： [TOC] 前述后的前述考虑到大疆的精灵可靠性安全性比较好，所以打算先用手头的P3P来做初期算法的验证（没办法，穷，买不起经纬系列，恩，花这么多钱买第三方飞行平台也不符合我们发展自主飞控的初衷），而精灵只支持Mobile sdk，也就是说这个算法必须得在手机上跑起来。所以，这跟树莓派有啥关系？事实上是先尝试了直接在安卓下移植，然而没跑起来，原因我也说不清楚，毕竟NDK开发我也只是入了个门，所以指不定是我没移植好，另一种可能就是算法在arm架构下有bug了，所以还是先在同为arm架构的树莓派上试试吧。下笔前纠结了下要不要把这部分记录下来，考虑到过程中碰到一些额外的值得记录的问题，还是记下吧。之所以怀疑arm下有问题，主要是DSST算法的源码里用到了SSE汇编指令加速（不然哪能这么高效），而SSE这玩意是intel家的，arm下可跑不了。遗憾的是intel在PC上是霸主，但在手机领域被arm吊打，我们用的手机从高端旗舰到华强北出的各种山寨，几乎清一色arm架构。幸而在参考资料博文[1]的指引下，找到一个支持arm的精简版源码（参考资料[2]）,支持arm的思路是用arm的NEON指令集实现SSE的同名函数，这部分工作又是另一位大佬做的（参考资料[3],现在最新的成果应该说是几位大佬的贡献了），只不过，这位大兄弟肯定没在arm架构下跑过，这个坑回头再说。但是精简工作做得很给力，原版源码复杂的工程结构被精简成了一个cpp文件和十个头文件，接口也写得更清晰易读，只需自己写个简单的main函数就能跑了。 移植环境 qtcreater+opencv3.2+树莓派3B(ubuntu mate 16.04) 说起树莓派，还真是身(la)材(ji)虽(ban)小(zi)，性(hui)能(wo)强(qing)劲(chun)！话说家乡山野间的树莓，这会正是好吃的时候呢~真想回到童年。 移植过程及所遇问题(1)、opencv库路径头文件路径配置后，二话不说先编译，报错：(具体是bits下哪个头文件忘了，发现解决了之后没法复现这个问题了orz~)1fatal error: bits/xxx.h: No such file or directory 解决方案：apt-get install gcc-multilib (2)、既然现在是arm平台下，那自然要把NEON的头文件包含进来，如图，注释掉sse.hpp里的emmintrin.h,再将SSE2NEON.h include进来。好像OK了？编译下喽~一堆报错~最亮眼的是这个：1#error You must enable NEON instructions(e.g.-mfloat-abi=softfp -mfpu=neon)to use arm_neon.h 解决方案：人家已经告诉你喽，在工程配置文件里添加QMAKE_CXXFLAGS += -mfloat-abi=softfp -mfpu=neon (3)、中间还有一个报错大致意思是在std这个namespace里没有fmax和fmin函数（写完博文翻看当时的移植笔记才发现漏了这个问题，懒得复现了。）解决方案：去掉std:: (4)、然而并没有那么顺利，报一堆错类似：1error dssttest uses VFP register arguments,fhog.o does not 解决方案：这个错误我也没搞明白，大致情况是系统哪里配置了使用硬件浮点运算单元，而此处被配置为软浮，所以报错，搜到网上解决方案是将/mkspecs/devices/linux-imx6-g++/qmake.conf里DISTRO_OPTS+=hard-float这句屏蔽掉，然而照做后并没有解决，所以我将QMAKE_CXXFLAGS += -mfloat-abi=softfp -mfpu=neon改为QMAKE_CXXFLAGS += -mfloat-abi=hard -mfpu=neon就OK了。有硬解为何还要用软解呢？不知道NEON是否一定需要使用软解，反正只有改成硬解才能顺利编译。 (5)、继续编译，报错：1&apos;_mm_rsqrt_ps&apos; was not declared in this scope 所以说那位写精简版源码的大佬显然并没有在arm下跑过，甚至大概就没有编译~原因是那会参考资料[3]那个工作还没有实现_mm_rsqrt_ps这个函数，尽管这位大佬在20天前更新过一次源码，但精力应该是放在了改进跟踪效果上（因为另一位博主说用过前一版的源码，效果并不理想，据其粗看这次更新主要调整了一些内部参数）。而SSE2NEON这个工作其实已经做出了更新，包含了更多的SSE的NEON实现。最近的一次更新就在4天前，目前支持95个SSE intrinsics函数,其中39个在arm上做了完整的测试，其余的实际效果还待测试。言下之意就是其余的并不保证没有bug。注意到最新的一次commits提到有些指令在32位机器上运行会有问题，而64位机器运行正常，目前fix了一部分。这个工作还需要也值得继续关注。解决方案：用最新的SSE2NEON.h进行替换。 这一次总算能顺利编译通过了，满心欢喜地点run，然而，在选定跟踪目标后就挂了，好气啊！大概是32位机器的锅吧~得找个64位的机器来试试，嗯，想起来了，室友的荣耀7就是~2333~事实证明64位机器是可行的！ 查看机器是不是64位机器的方法：1more /proc/cpuinfo 然而有些机器虽是64位的，但系统是32位的，就得用这个指令再确认下系统版本：1umane -a 参考资料 目标跟踪学习算法DSST（这位博主DSST分类下的几篇博文以及所引用的其他博主的相关博文都不错） TuringKi/fDSST_cpp - github sse2neon - github ARM上ROS的kinect配置 Qt5.5.1移植到freescale imx6 error compiling on ARM","tags":[{"name":"opencv","slug":"opencv","permalink":"http://sheng-blog.iego.cn/tags/opencv/"},{"name":"tracking","slug":"tracking","permalink":"http://sheng-blog.iego.cn/tags/tracking/"}]},{"title":"缘起","date":"2017-03-26T16:38:00.000Z","path":"2017/03/27/motivation(170327)/","text":"为什么搭建这个博客？最初使用新浪博客，发现插入代码太丑，遂转向CSDN。不得不说CSDN确实不错，平时搜索都是优先看它的，观感舒服。只是终究是公共博客网站，不够纯净。而且在上面发一些日志类的文章显然是不妥的。更重要的，我没法完整地保存他们。 遂有了动手搭建此站点的念头，记录一些折腾出的经验亦或生活所想。即使这个站点挂了，本地的仓库里仍然有我的一切。在这样一个相对僻静的空间里，有一种宁静而无拘无束的感觉。公共博客与这小站，大概就好比所谓超一线城市的房子和故乡丘陵山腰上的小楼房，而我更偏爱我那小楼房，开窗即是山水，抬头便是蓝天，闭眼只闻潺潺溪水、鸟语花香。 接下来，散落各处的经验笔记将按日期收归于此，或许偶尔也会有些深夜随想，也可能增加相册页，一切看心情~ 写于建站首日——2017-03-27 00:38","tags":[]},{"title":"QT使用ROS自带的opencv新建使用OPENCV的QT工程（None ROS）","date":"2017-03-18T11:33:00.000Z","path":"2017/03/18/QT使用ROS自带的opencv新建使用OPENCV的QT工程（None ROS）/","text":"ROS自带了OPENCV库，目前最新的kinetic使用的是OPENCV3.2.0,有时候想新建一个非ROS的QT project要使用OPENCV怎么办，显然，我们可以利用ROS里的库文件。 [toc] 配置步骤方法也很简单，ROS的OPENCV把头文件放在了/opt/ros/&lt; your_ros_version &gt;/include/opencv-xxx，而相应的库则在/opt/ros/&lt; your_ros_version &gt;/lib目录下。因此只需在新建QT工程后在工程配置文件中添加相应头文件路径并添加库之后就可以在工程里使用OPENCV了。如图：其中，每行末尾的\\表示未结束，LIBS +=-L指定库路径，随后的每一个-l指定库名称（去掉lib前缀和.so后缀后剩下的名字，如opencv_core3实际指库路径下的libopencv_core3.so文件）。然后就可以愉快地在QT工程中调用OPENCV啦！ 遇到问题起初在我添加了core,highgui,imgproc三个库后，就写了个测试程序如图：结果报错：1234undefined reference to symbol &apos;_ZN2cv6imreadERKNS_6StringEi&apos;//usr/local/lib/libopencv_imgcodecs.so.3.0: error adding symbols: DSO missing from command linecollect2: error: ld returned 1 exit status 后面才发现是少链接了opencv_imgcodecs3这个库，所以建议把opencv的库都链接进去。在lib目录下搜索opencv会搜出一大堆库，其中文件后缀为.so.x.x之类的是无需添加的。 另外，我忘了用ROS自带的opencv会不会碰到这个问题来着哈，至少在Ubuntu16.04 x64环境下直接安装opencv会碰到下面问题：一切都配置好了，编译却报错1error while loading shared libraries: libopencv_core.so.3.2: cannot open shared object file: No such file or directory 解决方案是找到该库所在目录，也就是opencv库的位置，在/etc/ld.so.conf.d/下面新建一个opencv.conf，里面写入该路径，最后执行下sudo ldconfig -v即可。 参考资料 Caffe: opencv error - Stack Overflow openCV program compile error “libopencv_core.so.2.4: cannot open shared object file: No such file or directory” in ubuntu 12.04 - Stack Overflow","tags":[{"name":"opencv","slug":"opencv","permalink":"http://sheng-blog.iego.cn/tags/opencv/"},{"name":"QT","slug":"QT","permalink":"http://sheng-blog.iego.cn/tags/QT/"}]},{"title":"Android studio2.2配置opencv for android（CMake方式）","date":"2017-02-24T11:06:00.000Z","path":"2017/02/24/Android studio2.2配置opencv for android（CMake方式）/","text":"由于项目需要不得不从原来的eclipse转到android studio下使用opencv for android，AS2.2已经开始支持CMake方式开发NDK，但网上大多数教程仍是使用Application.mk的老方式。而使用新方式不仅配置简单，而且可以获得native代码的自动提示、调试、自动补全。在参考了几篇博文下，终于搞出来了，其中碰到一些问题，这些博客并没有提到，所以特此写下整个配置过程及一些可能遇到的问题的解决方案。 博文结构： [TOC] 使用的软件版本 android studio 2.2.3 opencv for android （下载链接：opencv官网下载 ）我使用的版本是3.2.0 1、NDK的安装按草图步骤提示安装NDK、CMake和LLDB，安装好的NDK在Android SDK的sdk/ndk-bundle文件夹下。 2、native层使用opencv的配置过程首先新建项目，勾选C++的支持继续，Minimum sdk版本建议最好选择API21以上，除非手头设备安卓系统版本低再继续，最后这个配置界面千万记得勾选，我当时此处没勾，后面报错找了好久才找到解决方案，具体报错内容最后再说点开CMakeLists.txt文件，如图，在其中加入以下几句代码： 123set(OpenCV_DIR E:/Android/OpenCV-android-sdk/sdk/native/jni)find_package(OpenCV REQUIRED)target_link_libraries($&#123;OpenCV_LIBS&#125;) 然后在app下的build.gradle的android{defaultConfig{}}下加入如下代码（如图，注意大括号的包含关系）： 123ndk&#123; abiFilters &apos;armeabi-v7a&apos;&#125; 这里起一个过滤作用，这里应根据自己手机的CPU类型来进行选择。 *安卓设备的CPU类型： armeabiv-v7a: 第7代及以上的 ARM 处理器。2011年15月以后的生产的大部分Android设备都使用它. arm64-v8a: 第8代、64位ARM处理器，很少设备，三星 Galaxy S6是其中之一。 armeabi: 第5代、第6代的ARM处理器，早期的手机用的比较多。 x86: 平板、模拟器用得比较多。 x86_64: 64位的平板。 至此，只要包含opencv的头文件就可以愉快地在native层使用opencv了，当然，注意把函数写在extern “C” {}块里，其目的是使这部分代码块表按照类C的编译和连接规约来编译和连接，而不是C++的编译的连接规约。这样在类C的代码中就可以调用C++的函数or变量等。如果不这么写，程序会闪退，logcat报错“No implementation found for ‘you native method name’” 而且，使用时只需在java层用native关键字声明native层的函数，然后按ALT+ENTER选第一项即可在cpp文件里自动生成函数头，而不再需要像老方法一样使用javah来获得正确的函数头。 当然，如果需要调用摄像头和读取文件，别忘了在AndroidManifest.xml加上用到的权限： 1234567&lt;uses-permission android:name=&quot;android.permission.READ_EXTERNAL_STORAGE&quot;/&gt; &lt;uses-permission android:name=&quot;android.permission.CAMERA&quot;/&gt; &lt;uses-feature android:name=&quot;android.hardware.camera&quot; android:required=&quot;true&quot;/&gt; &lt;uses-feature android:name=&quot;android.hardware.camera.autofocus&quot; android:required=&quot;true&quot;/&gt; &lt;uses-feature android:name=&quot;android.hardware.camera.front&quot; android:required=&quot;true&quot;/&gt; &lt;uses-feature android:name=&quot;android.hardware.camera.front.autofocus&quot; android:required=&quot;true&quot;/&gt; 3、java层使用opencv的配置过程一般native层配合java层一起使用opencv才舒服，当然，简单一些的应用直接在java层使用opencv也是不错，若如此，前面native层的配置就不用了，当然，新建工程时自然也不需要勾选C++的支持。 我们把刚才OpenCV for Android目录下的java文件夹作为module导入进来。具体步骤是File-&gt;new-&gt;import module然后选择自己的路径如图：之后后面的不用修改，直接到最后Finish就行。 导入完成后注意需将将OpenCV这个module的build.gradle的版本信息改成跟app module的build.gradle的版本信息一样。 接着点击File-&gt;Project Structure，然后按照如图的顺序点击将OpenCV作为app module的Dependency导入进来至此，在代码里使用opencv就会有补全提示了，参考的博文里提到配置到这就可以顺利在java层使用opencv，然而经检验发现这还不够，虽然编译不报错，可以生成apk并顺利部署，但尝试运行却会闪退报错。因而还需继续进行配置。还需要在java层load一个libopencv_java3.so（3.0版本）或libopencv_java.so（2.4版本）库。 首先，在app/src/main目录下建立一个libs文件夹，然后再在其目录下建立子目录，对应指定的编译平台。然后前往本地的OpenCV for Android 的libs目录下选择对应的平台，我的是E:\\Android\\OpenCV-android-sdk\\sdk\\native\\libs\\armeabi-v7a，然后将里面的libopencv_java3.so库文件拷贝到我们刚才建立的文件夹下，如图：然后如图在app module的build.gradle的android{defaultConfig{}}加入如下代码： 1234sourceSets.main&#123; jniLibs.srcDir &apos;src/main/libs&apos; //set .so files directory to libs jni.srcDirs = [] //disable automatic ndk-build call&#125; 然后Sync Now，就可以在Android视图下看到app目录下多了一个jniLibs目录。之后，再在你想要使用jni的类中load opencv_java这个库就行了。如图： 4、遇到的一些问题以及解决方法 报错error cannot use typeid with fno rtti，原因是因为没有开rtti支持，也就是前面提到的新建项目时最后一个配置界面，解决办法：在app module的build.gradle的cmake {cppFlags “” }加入 “-frtti” Camera2 报错，原因是安卓从API21才开始引入Camera2，这就是前面建议最低SDK选择API21的原因，如果设备系统版本太低，那就删吧。 5、参考资料 Android Studio 2.2 让你5分钟配置好 OpenCV for Android（java层和native层都可以使用） 使用Android Studio 2.2和Cmake （CMakeLists）让OpenCV 飞起来 我的Android进阶之旅——&gt;Android 关于arm64-v8a、armeabi-v7a、armeabi、x86下的so文件兼容问题 Error: package android.hardware.camera2 does not exist OpenCV Error: Cannot use typeid with -fno-rtti","tags":[{"name":"opencv4android","slug":"opencv4android","permalink":"http://sheng-blog.iego.cn/tags/opencv4android/"}]},{"title":"ROS的开机自启脚本编写","date":"2017-02-15T11:33:00.000Z","path":"2017/02/15/ROS的开机自启脚本编写/","text":"用ROS开发好一个机器人后，在使用的时候每次都要先连上机器的网络再roslaunch太麻烦了，按产品的思路应该是按下电源键就OK才对。此外，若是还有上位机连着进行状态监视，万一主程序挂了，或者修改了程序要重新编译运行，那上位机这边的节点也要重新开一遍，太麻烦了吧。所以最好是在roslaunch之前单独开好一个roscore，这样修改下位机程序，上位机这边就不用重新开也能工作了。那就意味着机器上电后，我们要分两次ssh上去，一个开core，一个roslaunch。WTF！这种重复性的操作还是交给机器自己完成吧！（这篇博文的内容当时只用txt记录了过程，时间也有点久了，就保持原样吧~懒得排版~） 笔记1、联网检测代码段：123456789while true;doping -w 1 -c 1 192.168.1.132&gt;/dev/nullret=$?if [ $ret -eq 0 ]then printf &quot;$prefix is up&quot;break;else printf &quot;$prefix is down \\n&quot; fidone 2、在dash里搜索“启动应用程序”里将脚本设置为开机自启，脚本将在开机后后台运行，在命令前加上gnome-terminal -x可以实现在终端运行，但是比较建议在脚本里需要在终端执行的地方加这个指令。 3、这种方式的开机自启需要系统打开图形界面，比如树莓派的Ubuntu mate系统里确保graphical enable，但具体有没有显示屏存在并不重要。另外需要注意的是如果安装了xrdp这种远程桌面的话，在同一个IP开多个窗口远程登录看到的是同一块桌面，而不同IP则看到的是不同桌面，我们设置的开机启动程序在每一块桌面启动时都会被执行！而vnc则有且仅有一块桌面，与HDMI输出保持一致。 4、在同一个脚本里仅能执行一个不return的指令，比如在同一个脚本里先roscore再roslaunch是不行的，实际效果是只执行到roscore,除非ctrl+c结束core,脚本才会继续往下执行。因此，若要启动一个core和一个roslaunch需要添加两个开机启动脚本。 5、强大的screen指令：前面提到脚本在终端执行，但是在随后我们ssh后却无法操控该终端，此时screen指令可以解决这个问题。新建一个screen再在里面操作即可方便后续attach回去，脚本里gnome-terminal -x screen -S windowname /the/path/of/the/shell 即可，分成两条写{gnome-terminal -x screen -S windowname接/the/path/of/the/shell}是不行的。 6、使用上面这种开screen就运行脚本的方式有一个问题，比如roslaunch里某环节报错挂了，screen会话将直接被终止，我们无从获知程序报错的原因。因此不能按上述命令写，而应将新建screen会话和执行脚本分开，正确的方式是：gnome-terminal -x screen -S windowname接gnome-terminal -x screen -S windowname -X screen /the/path/of/the/shell。其中screen的 -X 参数意思是指定在哪个screen中运行某个指令。 7、尽管我们加了gnome-terminal -x指定了后面的命令需在一个终端里执行，但screen 后紧跟的指令执行的时机是在终端执行.bashrc文件之前，所以我们需要在脚本里自行source一些ROS配置文件，不要忘了export ROS_MASTER_URI=http://pi:11311export ROS_IP=10.42.0.64这两个环境变量，否则其他计算机将无法与其正常通信。正是这一feature使得我们若要启动一个core和一个roslaunch的话需要用到四个脚本！ 8、必须保证先开core，因此可在launch的脚本里加延时，延时不能太短，否则core还没开好就roslaunch了同样会死得很难看，我看到的现象是两个窗口里都在反复restart。目前使用25s延时，差不多。20s有点险。 当前使用的脚本newscreen_core123456789101112#!/bin/bash while true;doping -w 1 -c 1 10.42.0.1&gt;/dev/nullret=$?if [ $ret -eq 0 ]then printf &quot;$prefix is up&quot;break;else printf &quot;$prefix is down \\n&quot; fidonemate-terminal -x screen -S core ~/auto_runing/core_ros#mate-terminal -x screen -S core -X screen ~/auto_runing/core_ros core_ros12345678#!/bin/bash source /opt/ros/kinetic/setup.bash source /home/pi/.bashrc source /home/pi/catkin_ws/devel/setup.bash cd /home/pi/catkin_wsexport ROS_MASTER_URI=http://10.42.0.1:11311export ROS_IP=10.42.0.1roscore newscreen_quad12345678910111213#!/bin/bash while true;doping -w 1 -c 1 10.42.0.1&gt;/dev/nullret=$?if [ $ret -eq 0 ]then printf &quot;$prefix is up&quot;break;else printf &quot;$prefix is down \\n&quot; fidonesleep 25smate-terminal -x screen -S quadmate-terminal -x screen -S quad -X screen ~/auto_runing/quadrotor quadrotor12345678#!/bin/bash source /opt/ros/kinetic/setup.bash source /home/pi/.bashrc source /home/pi/catkin_ws/devel/setup.bash cd /home/pi/catkin_wsexport ROS_MASTER_URI=http://10.42.0.1:11311export ROS_IP=10.42.0.1roslaunch planning start_test.launch","tags":[{"name":"ROS","slug":"ROS","permalink":"http://sheng-blog.iego.cn/tags/ROS/"}]},{"title":"小四轴9轴数据融合成功","date":"2015-11-22T12:10:15.000Z","path":"2015/11/22/小四轴9轴数据融合成功/","text":"前两天二代硬件终于到齐了，室友风风火火焊出来两架新硬件，没想到电路板上产生的磁场比地磁场还强，导致磁力计数据变化不明显，害得我们以为是焊接问题（毕竟DataSheet说不推荐手工焊接且温度不能超过260度），算是坑了室友一把呵呵~，其实进行一下校正就好了。磁力计的问题解决，果断换上早写好的九轴融合代码，妥妥的。11月22日，值得纪念的日子，算是完成了此前计划的12月前搞定姿态解算的计划。晒个图喽~吐槽下二代买的新桨叶，又硬又丑又效率低，一代的桨叶电机给4成占空比就飞起来了，新桨叶要加到7成~而且震动比旧桨高出N倍，导致姿态解算结果有1度左右的抖动。最重要的是卡在电机上拆不下来了。。。。附所用九轴融合算法图解：另有梯度下降法版本：补充：随后发现高兴得太早，当开启电机之后，由于电机产生的磁场，磁力计根本无法分辨方向，由于电机磁场是变化的，所以无法通过校正来排除干扰。在随后的第三版硬件里尝试过使用单独一块小板放置磁力计，并架离电机平面（因为电机平面处受影响最大，通常采用架离处理，如大疆精灵系列就将磁力计隐藏在了脚架中），然而在能接受的高度范围内，依然无法得到有效数据。所以在PCB四轴上应该是无法使用磁力计的，目前也未看到市面上有使用了磁力计的PCB小四轴出现。另：小四轴程序上主要是两大部分，一个是姿态解算，一个是PID控制。由于PID控制没什么可总结的，一成不变的公式一套就是，主要是参数调整比较磨人。所以直接在此补充PID框图如下：单环PID控制，参数好调，但效果不稳定：串级PID，内环难调，效果很赞：","tags":[{"name":"多旋翼","slug":"多旋翼","permalink":"http://sheng-blog.iego.cn/tags/多旋翼/"}]},{"title":"姿态解算知识（三）-陀螺仪加速度计6轴数据融合","date":"2015-11-15T17:50:29.000Z","path":"2015/11/16/姿态解算知识（三）-陀螺仪加速度计6轴数据融合/","text":"这么久的惯导总算是没白看，加上一篇博客的指点，这两天把Mahony的九轴数据融合算法看懂了。可惜第二版硬件还没到，磁力计用不了，没法验证效果~今天先总结下陀螺仪和加速度计的六轴数据融合。 加计和陀螺仪都能计算出姿态，但为何要对它们融合呢，是因为加速度计对振动之类的扰动很敏感，但长期数据计算出的姿态可信，而陀螺仪虽然对振动这些不敏感，但长期使用陀螺仪会出现漂移，因此我们要进行互补，短期相信陀螺，长期相信加计。不过，其实加计无法对航向角进行修正，修正航向角需要磁力计，也就是下次要总结的9轴数据融合。 在融合之前先要对传感器原始数据进行一些处理。理想情况下，加速度计水平放置时，XY轴应该是0输出的，仅Z轴输出1个G，因此，我们需要对加速度计进行XY轴的零点校准（注意Z轴可不能一起校准去了~）；同样的，陀螺仪在水平静止放置时各轴输出应为0，因此需对陀螺仪进行三轴的校准。方法就是把机体标准水平静止放置时采集它个一两百次数据求个平均作为校准值保存起来喽，然后工作状态下各轴输出的数据就是采集来的数据减去校准值喽。仅此还不够，陀螺仪不进行滤波还可以接受，但加速度计噪声比较大，所以至少也得来个滑动窗口滤波，我用了20深度的滑动窗口，数据还是有很大波动，不过最后计算出的姿态角只有0.3度左右的抖动（我看大家一般都是建议8深度就够了，所以单滑动窗口滤波效果是没法做到更好了，可以考虑加个卡尔曼滤波？还没研究，不过这样处理器运算量就上去了）。（11.28补充：后面改对加计使用8深度滑动滤波，陀螺仪进行16阶凯撒窗滤波后只有0.1不到的波动，不过凯撒滤波参数的整定还不会，用的别人整定的一组参数，近期继续研究）。滤波效果如图：接下来上六轴数据融合代码：（代码来源网络，我在前人的基础上再加些注释，稍作改动）1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071#defineKp 10.0f // 这里的KpKi是用于调整加速度计修正陀螺仪的速度#defineKi 0.008f #definehalfT 0.001f // 采样周期的一半，用于求解四元数微分方程时计算角增量floatq0 = 1, q1 = 0, q2 = 0, q3 = 0; // 初始姿态四元数，由上篇博文提到的变换四元数公式得来floatexInt = 0, eyInt = 0, ezInt = 0; //当前加计测得的重力加速度在三轴上的分量 //与用当前姿态计算得来的重力在三轴上的分量的误差的积分voidIMUupdate(float gx, float gy, float gz, float ax, float ay, float az)//g表陀螺仪，a表加计&#123; float q0temp,q1temp,q2temp,q3temp;//四元数暂存变量，求解微分方程时要用 float norm; //矢量的模或四元数的范数 float vx, vy, vz;//当前姿态计算得来的重力在三轴上的分量 float ex, ey, ez;//当前加计测得的重力加速度在三轴上的分量 //与用当前姿态计算得来的重力在三轴上的分量的误差 // 先把这些用得到的值算好 float q0q0 = q0*q0; float q0q1 = q0*q1; float q0q2 = q0*q2; float q1q1 = q1*q1; float q1q3 = q1*q3; float q2q2 = q2*q2; float q2q3 = q2*q3; float q3q3 = q3*q3; if(ax*ay*az==0)//加计处于自由落体状态时不进行姿态解算，因为会产生分母无穷大的情况 return; norm = sqrt(ax*ax + ay*ay + az*az);//单位化加速度计， ax = ax /norm;// 这样变更了量程也不需要修改KP参数，因为这里归一化了 ay = ay / norm; az = az / norm; //用当前姿态计算出重力在三个轴上的分量， //参考坐标n系转化到载体坐标b系的用四元数表示的方向余弦矩阵第三列即是（博文一中有提到） vx = 2*(q1q3 - q0q2); vy = 2*(q0q1 + q2q3); vz = q0q0 - q1q1 - q2q2 + q3q3 ; //计算测得的重力与计算得重力间的误差，向量外积可以表示这一误差 //原因我理解是因为两个向量是单位向量且sin0等于0 //不过要是夹角是180度呢~这个还没理解 ex = (ay*vz - az*vy) ; ey = (az*vx - ax*vz) ; ez = (ax*vy - ay*vx) ; exInt = exInt + ex * Ki; //对误差进行积分 eyInt = eyInt + ey * Ki; ezInt = ezInt + ez * Ki; // adjusted gyroscope measurements gx = gx + Kp*ex + exInt; //将误差PI后补偿到陀螺仪，即补偿零点漂移 gy = gy + Kp*ey + eyInt; gz = gz + Kp*ez + ezInt; //这里的gz由于没有观测者进行矫正会产生漂移，表现出来的就是积分自增或自减 //下面进行姿态的更新，也就是四元数微分方程的求解 q0temp=q0;//暂存当前值用于计算 q1temp=q1;//网上传的这份算法大多没有注意这个问题，在此更正 q2temp=q2; q3temp=q3; //采用一阶毕卡解法，相关知识可参见《惯性器件与惯性导航系统》P212 q0 = q0temp + (-q1temp*gx - q2temp*gy -q3temp*gz)*halfT; q1 = q1temp + (q0temp*gx + q2temp*gz -q3temp*gy)*halfT; q2 = q2temp + (q0temp*gy - q1temp*gz +q3temp*gx)*halfT; q3 = q3temp + (q0temp*gz + q1temp*gy -q2temp*gx)*halfT; //单位化四元数在空间旋转时不会拉伸，仅有旋转角度，这类似线性代数里的正交变换 norm = sqrt(q0*q0 + q1*q1 + q2*q2 + q3*q3); q0 = q0 / norm; q1 = q1 / norm; q2 = q2 / norm; q3 = q3 / norm; //四元数到欧拉角的转换，公式推导见博文一 //其中YAW航向角由于加速度计对其没有修正作用，因此此处直接用陀螺仪积分代替 Q_ANGLE.Z = GYRO_I.Z; // yaw Q_ANGLE.Y = asin(-2 * q1 * q3 + 2 * q0* q2)*57.3; // pitch Q_ANGLE.X = atan2(2 * q2 * q3 + 2 * q0 * q1,-2 * q1 * q1 - 2 * q2* q2 + 1)* 57.3; // roll&#125; 上述代码图解：新浪博客插代码好不方便，格式全乱了。最后忘了说了，千万别忘了传入的陀螺仪数据需乘一个系数将其转化为弧度制角速度！！！补充，梯度下降法六轴融合图解：","tags":[{"name":"多旋翼","slug":"多旋翼","permalink":"http://sheng-blog.iego.cn/tags/多旋翼/"}]},{"title":"姿态解算基础知识（二）-旋转矢量坐标变换的四元数描述的验证","date":"2015-11-13T17:13:29.000Z","path":"2015/11/14/姿态解算基础知识（二）-旋转矢量坐标变换的四元数描述的验证/","text":"补充下四元数的知识及上篇博文提到的旋转矢量坐标变换的四元数描述的推导过程。 四元数q可以看出由一个实数和一个三维矢量组成： 惯性导航系统分平台式惯性导航系统和捷联式惯性导航系统。平台式是有一个由陀螺仪控制的实体平台保证加速度计能始终测得在导航坐标系下的各轴加速度值，而载体姿态通过读取平台刻度即可获得。而捷联式惯性导航系统则没有实体平台，加计测得的是载体坐标系下的各轴加速度，我们需要通过数学办法进行坐标系变换将加计的数据转换成导航坐标系下的各轴加速度值，相当于用数学办法构建一个“平台”。 SO，先来解决坐标变换的表示。先从二维平面OXY坐标系讲起：当OXY逆时针旋转α度时，同一矢量R在不同坐标下的表示：根据方向余弦矩阵我们可以得到三个姿态角方向余弦矩阵参与运算的话计算量比较大，所以我们用四元数进行坐标变换的运算（四元数的概念性质自行百度，或者下篇补充吧），它与方向余弦矩阵描述的关系及变换公式的推导如下：事实上四轴姿态解算就加计和陀螺的融合而言要用到的是导航坐标系到载体坐标系的变换，推导过程一样。 我们追求的并不是解决问题，而应是更好地解决问题，没有扎实的基础保障，就无法俯视我们要解决的问题，找到最好的办法。尽管不俯视，一样能解决这个问题，但却心虚。一个项目能用到多少知识？可以认为很多也可以认为很少，多，那是基础牢，做得细致。少，那仅是为了解决问题而解决问题。这段话写得乱，深夜随想，希望未来的自己能懂。从现在起，三年时间，认真沉淀，不急躁，不急功近利！","tags":[{"name":"多旋翼","slug":"多旋翼","permalink":"http://sheng-blog.iego.cn/tags/多旋翼/"}]},{"title":"姿态解算基础知识（一）","date":"2015-11-10T17:02:22.000Z","path":"2015/11/11/姿态解算基础知识（一）/","text":"目前，对于姿态解算已经有些认识，至少可以看懂别人的开源代码。感觉我现在知道的东西像一堆点连起来的线段，还有些地方是散的，没有联通。暂且在这记录下。 首先，四轴上用到mpu6050进行姿态解算属于惯性导航的范畴，为了了解基本概念跑去图书馆借了四本书回来（这里吐槽下图书馆，《卡尔曼滤波和组合导航原理》在图书检索系统显示在阅览室，十几层阅览室你让我上哪找去），四本里面科学出版社的《惯性器件与惯性导航系统》比较有感觉。惯性导航的目的主要包括输出航向、姿态、速度以及自主定位信息。做小四轴仅仅只需要姿态而已，想想用惯性导航进行定位就吓人~ 惯性导航系统分平台式惯性导航系统和捷联式惯性导航系统。平台式是有一个由陀螺仪控制的实体平台保证加速度计能始终测得在导航坐标系下的各轴加速度值，而载体姿态通过读取平台刻度即可获得。而捷联式惯性导航系统则没有实体平台，加计测得的是载体坐标系下的各轴加速度，我们需要通过数学办法进行坐标系变换将加计的数据转换成导航坐标系下的各轴加速度值，相当于用数学办法构建一个“平台”。 SO，先来解决坐标变换的表示。先从二维平面OXY坐标系讲起：当OXY逆时针旋转α度时，同一矢量R在不同坐标下的表示：根据方向余弦矩阵我们可以得到三个姿态角方向余弦矩阵参与运算的话计算量比较大，所以我们用四元数进行坐标变换的运算（四元数的概念性质自行百度，或者下篇补充吧），它与方向余弦矩阵描述的关系及变换公式的推导如下：事实上四轴姿态解算就加计和陀螺的融合而言要用到的是导航坐标系到载体坐标系的变换，推导过程一样。 我们追求的并不是解决问题，而应是更好地解决问题，没有扎实的基础保障，就无法俯视我们要解决的问题，找到最好的办法。尽管不俯视，一样能解决这个问题，但却心虚。一个项目能用到多少知识？可以认为很多也可以认为很少，多，那是基础牢，做得细致。少，那仅是为了解决问题而解决问题。这段话写得乱，深夜随想，希望未来的自己能懂。从现在起，三年时间，认真沉淀，不急躁，不急功近利！","tags":[{"name":"多旋翼","slug":"多旋翼","permalink":"http://sheng-blog.iego.cn/tags/多旋翼/"}]},{"title":"小四轴-总计划","date":"2015-10-26T15:54:44.000Z","path":"2015/10/26/小四轴总计划/","text":"在博客上看到有位大神写下了整个四轴制作笔记，想到自己做了不少东西但在规划时间方面和经验总结方面很欠缺，或者说自己做东西太闲散了。所以也来定期记些东西，也记些经验，免得以后同样的错重犯什么的。 从22号室友焊好硬件到现在，电机已能正常驱动，只可惜机尾电机明显有毛病，要换，等经费喽、mpu6050、bmp085原始数据已经能正确读取。只是hmc5883读回来的一直是ff，晚上仔细检查基本确定是电路原理图弄错了（咳，这芯片的焊接被冤枉两次了，浪费两块），室友这次的表现真心对不起“硬件小王子”的称号啊，以后还得对着datasheet典型应用电路给他检查一遍才行，以前还真没想过要用典型应用电路来检查队友原理图，一直觉着硬件出错只能是焊错或者元件封装用错，连线连错之类的很难检查的问题，就懒得给他检查了。 代码码多了，什么bug都能遇到，stm32定时器定个500ms居然实际出来2s，慢了四倍，要说是时钟配置问题的话，同样程序下载到另一块板子上却完全正常，要说是外部晶振的问题，串口1串口2都能正常使用，我是真想不出为何了，只能暂时认为是单片机问题了。不换了，反正mpu6050能正常读取，先调着，等第二版硬件。​ 计划： 1、12月前搞定姿态解算吧，虽然有开源的姿态解算算法，但看不懂，若是直接移植用着，网上基本只能找到陀螺仪和加计的融合算法，要加磁力计和气压计的话还是无从下手，所以明天去图书馆借些惯性导航还有数字滤波方面的书​（已物色四本哈哈，话说居然还有书是不让借的。。。），只求看懂滤波和融合的原理，看懂开源代码。 2、姿态调完了研究控制，目前先不去关心控制方面的东西，1个月时间飞起来，寒假之前实现各个方向控制以及定点悬停。","tags":[{"name":"多旋翼","slug":"多旋翼","permalink":"http://sheng-blog.iego.cn/tags/多旋翼/"}]}]