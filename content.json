[{"title":"DSST折腾笔记（一）：树莓派3上的移植","date":"2017-04-02T02:10:13.000Z","path":"2017/04/02/DSST折腾笔记（一）：树莓派3上的移植/","text":"DSST（文章全名Accurate Scale Estimation for Robust Visual Tracking）是视觉目标跟踪VOT2014竞赛的冠军。实测实时性好，跟踪效果着实很赞(当然就跟踪效果而言还是逊色于TLD，在一次测试里，我起身把待洗衣服拿去洗衣房，然后回来，TLD还是准确地重新把我的脸给找了出来，继续追踪！这个过程少说也有四五分钟，这么长时间的目标丢失，TLD居然没挂！TLD已是2009年的工作了，算是比较久远的了，却能火到现在，可见其地位)。回到DSST，这篇算法是基于MOSSE的改进，突出内容是加入了尺度变换，文中指出该算法亮点是大部分算法只要是多尺度问题，都可以通过DSST中的尺度部分来解决。2015年开始tracking就被深度学习的算法攻陷了，效果确实很赞，然而受硬件限制，也受速度限制，不适合在移动端跑。所以当前来说DSST应是最契合我的需求的了。先把它移植过来用着，后面再好好研究下代码，希望把深度信息利用进去进一步提升工程上的跟踪效果。 博文结构： [TOC] 前述后的前述考虑到大疆的精灵可靠性安全性比较好，所以打算先用手头的P3P来做初期算法的验证（没办法，穷，买不起经纬系列，恩，花这么多钱买第三方飞行平台也不符合我们发展自主飞控的初衷），而精灵只支持Mobile sdk，也就是说这个算法必须得在手机上跑起来。所以，这跟树莓派有啥关系？事实上是先尝试了直接在安卓下移植，然而没跑起来，原因我也说不清楚，毕竟NDK开发我也只是入了个门，所以指不定是我没移植好，另一种可能就是算法在arm架构下有bug了，所以还是先在同为arm架构的树莓派上试试吧。下笔前纠结了下要不要把这部分记录下来，考虑到过程中碰到一些额外的值得记录的问题，还是记下吧。之所以怀疑arm下有问题，主要是DSST算法的源码里用到了SSE汇编指令加速（不然哪能这么高效），而SSE这玩意是intel家的，arm下可跑不了。遗憾的是intel在PC上是霸主，但在手机领域被arm吊打，我们用的手机从高端旗舰到华强北出的各种山寨，几乎清一色arm架构。幸而在参考资料博文[1]的指引下，找到一个支持arm的精简版源码（参考资料[2]）,支持arm的思路是用arm的NEON指令集实现SSE的同名函数，这部分工作又是另一位大佬做的（参考资料[3],现在最新的成果应该说是几位大佬的贡献了），只不过，这位大兄弟肯定没在arm架构下跑过，这个坑回头再说。但是精简工作做得很给力，原版源码复杂的工程结构被精简成了一个cpp文件和十个头文件，接口也写得更清晰易读，只需自己写个简单的main函数就能跑了。 移植环境 qtcreater+opencv3.2+树莓派3B(ubuntu mate 16.04) 说起树莓派，还真是身(la)材(ji)虽(ban)小(zi)，性(hui)能(wo)强(qing)劲(chun)！话说家乡山野间的树莓，这会正是好吃的时候呢~真想回到童年。 移植过程及所遇问题(1)、opencv库路径头文件路径配置后，二话不说先编译，报错：(具体是bits下哪个头文件忘了，发现解决了之后没法复现这个问题了orz~)1fatal error: bits/xxx.h: No such file or directory 解决方案：apt-get install gcc-multilib (2)、既然现在是arm平台下，那自然要把NEON的头文件包含进来，如图，注释掉sse.hpp里的emmintrin.h,再将SSE2NEON.h include进来。好像OK了？编译下喽~一堆报错~最亮眼的是这个：1#error You must enable NEON instructions(e.g.-mfloat-abi=softfp -mfpu=neon)to use arm_neon.h 解决方案：人家已经告诉你喽，在工程配置文件里添加QMAKE_CXXFLAGS += -mfloat-abi=softfp -mfpu=neon (3)、然而并没有那么顺利，报一堆错类似：1error dssttest uses VFP register arguments,fhog.o does not 解决方案：这个错误我也没搞明白，大致情况是系统哪里配置了使用硬件浮点运算单元，而此处被配置为软浮，所以报错，搜到网上解决方案是将/mkspecs/devices/linux-imx6-g++/qmake.conf里DISTRO_OPTS+=hard-float这句屏蔽掉，然而照做后并没有解决，所以我将QMAKE_CXXFLAGS += -mfloat-abi=softfp -mfpu=neon改为QMAKE_CXXFLAGS += -mfloat-abi=hard -mfpu=neon就OK了。有硬解为何还要用软解呢？不知道NEON是否一定需要使用软解，反正只有改成硬解才能顺利编译。 (4)、继续编译，报错：1&apos;_mm_rsqrt_ps&apos; was not declared in this scope 所以说那位写精简版源码的大佬显然并没有在arm下跑过，甚至大概就没有编译~原因是那会参考资料[3]那个工作还没有实现_mm_rsqrt_ps这个函数，尽管这位大佬在20天前更新过一次源码，但精力应该是放在了改进跟踪效果上（因为另一位博主说用过前一版的源码，效果并不理想，据其粗看这次更新主要调整了一些内部参数）。而SSE2NEON这个工作其实已经做出了更新，包含了更多的SSE的NEON实现。最近的一次更新就在4天前，目前支持95个SSE intrinsics函数,其中39个在arm上做了完整的测试，其余的实际效果还待测试。言下之意就是其余的并不保证没有bug。注意到最新的一次commits提到有些指令在32位机器上运行会有问题，而64位机器运行正常，目前fix了一部分。这个工作还需要也值得继续关注。解决方案：用最新的SSE2NEON.h进行替换。 这一次总算能顺利编译通过了，满心欢喜地点run，然而，在选定跟踪目标后就挂了，好气啊！大概是32位机器的锅吧~得找个64位的机器来试试，嗯，想起来了，室友的荣耀7就是~2333~事实证明64位机器是可行的！ 移植过程及所遇问题 目标跟踪学习算法DSST（这位博主DSST分类下的几篇博文以及所引用的其他博主的相关博文都不错） TuringKi/fDSST_cpp - github sse2neon - github ARM上ROS的kinect配置 Qt5.5.1移植到freescale imx6 error compiling on ARM","tags":[{"name":"opencv","slug":"opencv","permalink":"http://sheng-blog.iego.cn/tags/opencv/"},{"name":"tracking","slug":"tracking","permalink":"http://sheng-blog.iego.cn/tags/tracking/"}]},{"title":"缘起","date":"2017-03-26T16:38:00.000Z","path":"2017/03/27/motivation(170327)/","text":"为什么搭建这个博客？最初使用新浪博客，发现插入代码太丑，遂转向CSDN。不得不说CSDN确实不错，平时搜索都是优先看它的，观感舒服。只是终究是公共博客网站，不够纯净。而且在上面发一些日志类的文章显然是不妥的。更重要的，我没法完整地保存他们。 遂有了动手搭建此站点的念头，记录一些折腾出的经验亦或生活所想。即使这个站点挂了，本地的仓库里仍然有我的一切。在这样一个相对僻静的空间里，有一种宁静而无拘无束的感觉。公共博客与这小站，大概就好比所谓超一线城市的房子和故乡丘陵山腰上的小楼房，而我更偏爱我那小楼房，开窗即是山水，抬头便是蓝天，闭眼只闻潺潺溪水、鸟语花香。 接下来，散落各处的经验笔记将按日期收归于此，或许偶尔也会有些深夜随想，也可能增加相册页，一切看心情~ 写于建站首日——2017-03-27 00:38","tags":[]},{"title":"QT使用ROS自带的opencv新建使用OPENCV的QT工程（None ROS）","date":"2017-03-18T11:33:00.000Z","path":"2017/03/18/QT使用ROS自带的opencv新建使用OPENCV的QT工程（None ROS）/","text":"ROS自带了OPENCV库，目前最新的kinetic使用的是OPENCV3.2.0,有时候想新建一个非ROS的QT project要使用OPENCV怎么办，显然，我们可以利用ROS里的库文件。 [toc] 配置步骤方法也很简单，ROS的OPENCV把头文件放在了/opt/ros/&lt; your_ros_version &gt;/include/opencv-xxx，而相应的库则在/opt/ros/&lt; your_ros_version &gt;/lib目录下。因此只需在新建QT工程后在工程配置文件中添加相应头文件路径并添加库之后就可以在工程里使用OPENCV了。如图：其中，每行末尾的\\表示未结束，LIBS +=-L指定库路径，随后的每一个-l指定库名称（去掉lib前缀和.so后缀后剩下的名字，如opencv_core3实际指库路径下的libopencv_core3.so文件）。然后就可以愉快地在QT工程中调用OPENCV啦！ 遇到问题起初在我添加了core,highgui,imgproc三个库后，就写了个测试程序如图：结果报错：1234undefined reference to symbol &apos;_ZN2cv6imreadERKNS_6StringEi&apos;//usr/local/lib/libopencv_imgcodecs.so.3.0: error adding symbols: DSO missing from command linecollect2: error: ld returned 1 exit status 后面才发现是少链接了opencv_imgcodecs3这个库，所以建议把opencv的库都链接进去。在lib目录下搜索opencv会搜出一大堆库，其中文件后缀为.so.x.x之类的是无需添加的。 另外，我忘了用ROS自带的opencv会不会碰到这个问题来着哈，至少在Ubuntu16.04 x64环境下直接安装opencv会碰到下面问题：一切都配置好了，编译却报错1error while loading shared libraries: libopencv_core.so.3.2: cannot open shared object file: No such file or directory 解决方案是找到该库所在目录，也就是opencv库的位置，在/etc/ld.so.conf.d/下面新建一个opencv.conf，里面写入该路径，最后执行下sudo ldconfig -v即可。 参考资料 Caffe: opencv error - Stack Overflow openCV program compile error “libopencv_core.so.2.4: cannot open shared object file: No such file or directory” in ubuntu 12.04 - Stack Overflow","tags":[{"name":"opencv","slug":"opencv","permalink":"http://sheng-blog.iego.cn/tags/opencv/"},{"name":"QT","slug":"QT","permalink":"http://sheng-blog.iego.cn/tags/QT/"}]},{"title":"Android studio2.2配置opencv for android（CMake方式）","date":"2017-02-24T11:06:00.000Z","path":"2017/02/24/Android studio2.2配置opencv for android（CMake方式）/","text":"由于项目需要不得不从原来的eclipse转到android studio下使用opencv for android，AS2.2已经开始支持CMake方式开发NDK，但网上大多数教程仍是使用Application.mk的老方式。而使用新方式不仅配置简单，而且可以获得native代码的自动提示、调试、自动补全。在参考了几篇博文下，终于搞出来了，其中碰到一些问题，这些博客并没有提到，所以特此写下整个配置过程及一些可能遇到的问题的解决方案。 博文结构： [TOC] 使用的软件版本 android studio 2.2.3 opencv for android （下载链接：opencv官网下载 ）我使用的版本是3.2.0 1、NDK的安装按草图步骤提示安装NDK、CMake和LLDB，安装好的NDK在Android SDK的sdk/ndk-bundle文件夹下。 2、native层使用opencv的配置过程首先新建项目，勾选C++的支持继续，Minimum sdk版本建议最好选择API21以上，除非手头设备安卓系统版本低再继续，最后这个配置界面千万记得勾选，我当时此处没勾，后面报错找了好久才找到解决方案，具体报错内容最后再说点开CMakeLists.txt文件，如图，在其中加入以下几句代码： 123set(OpenCV_DIR E:/Android/OpenCV-android-sdk/sdk/native/jni)find_package(OpenCV REQUIRED)target_link_libraries($&#123;OpenCV_LIBS&#125;) 然后在app下的build.gradle的android{defaultConfig{}}下加入如下代码（如图，注意大括号的包含关系）： 123ndk&#123; abiFilters &apos;armeabi-v7a&apos;&#125; 这里起一个过滤作用，这里应根据自己手机的CPU类型来进行选择。 *安卓设备的CPU类型： armeabiv-v7a: 第7代及以上的 ARM 处理器。2011年15月以后的生产的大部分Android设备都使用它. arm64-v8a: 第8代、64位ARM处理器，很少设备，三星 Galaxy S6是其中之一。 armeabi: 第5代、第6代的ARM处理器，早期的手机用的比较多。 x86: 平板、模拟器用得比较多。 x86_64: 64位的平板。 至此，只要包含opencv的头文件就可以愉快地在native层使用opencv了，当然，注意把函数写在extern “C” {}块里，其目的是使这部分代码块表按照类C的编译和连接规约来编译和连接，而不是C++的编译的连接规约。这样在类C的代码中就可以调用C++的函数or变量等。如果不这么写，程序会闪退，logcat报错“No implementation found for ‘you native method name’” 而且，使用时只需在java层用native关键字声明native层的函数，然后按ALT+ENTER选第一项即可在cpp文件里自动生成函数头，而不再需要像老方法一样使用javah来获得正确的函数头。 当然，如果需要调用摄像头和读取文件，别忘了在AndroidManifest.xml加上用到的权限： 1234567&lt;uses-permission android:name=&quot;android.permission.READ_EXTERNAL_STORAGE&quot;/&gt; &lt;uses-permission android:name=&quot;android.permission.CAMERA&quot;/&gt; &lt;uses-feature android:name=&quot;android.hardware.camera&quot; android:required=&quot;true&quot;/&gt; &lt;uses-feature android:name=&quot;android.hardware.camera.autofocus&quot; android:required=&quot;true&quot;/&gt; &lt;uses-feature android:name=&quot;android.hardware.camera.front&quot; android:required=&quot;true&quot;/&gt; &lt;uses-feature android:name=&quot;android.hardware.camera.front.autofocus&quot; android:required=&quot;true&quot;/&gt; 3、java层使用opencv的配置过程一般native层配合java层一起使用opencv才舒服，当然，简单一些的应用直接在java层使用opencv也是不错，若如此，前面native层的配置就不用了，当然，新建工程时自然也不需要勾选C++的支持。 我们把刚才OpenCV for Android目录下的java文件夹作为module导入进来。具体步骤是File-&gt;new-&gt;import module然后选择自己的路径如图：之后后面的不用修改，直接到最后Finish就行。 导入完成后注意需将将OpenCV这个module的build.gradle的版本信息改成跟app module的build.gradle的版本信息一样。 接着点击File-&gt;Project Structure，然后按照如图的顺序点击将OpenCV作为app module的Dependency导入进来至此，在代码里使用opencv就会有补全提示了，参考的博文里提到配置到这就可以顺利在java层使用opencv，然而经检验发现这还不够，虽然编译不报错，可以生成apk并顺利部署，但尝试运行却会闪退报错。因而还需继续进行配置。还需要在java层load一个libopencv_java3.so（3.0版本）或libopencv_java.so（2.4版本）库。 首先，在app/src/main目录下建立一个libs文件夹，然后再在其目录下建立子目录，对应指定的编译平台。然后前往本地的OpenCV for Android 的libs目录下选择对应的平台，我的是E:\\Android\\OpenCV-android-sdk\\sdk\\native\\libs\\armeabi-v7a，然后将里面的libopencv_java3.so库文件拷贝到我们刚才建立的文件夹下，如图：然后如图在app module的build.gradle的android{defaultConfig{}}加入如下代码： 1234sourceSets.main&#123; jniLibs.srcDir &apos;src/main/libs&apos; //set .so files directory to libs jni.srcDirs = [] //disable automatic ndk-build call&#125; 然后Sync Now，就可以在Android视图下看到app目录下多了一个jniLibs目录。之后，再在你想要使用jni的类中load opencv_java这个库就行了。如图： 4、遇到的一些问题以及解决方法 报错error cannot use typeid with fno rtti，原因是因为没有开rtti支持，也就是前面提到的新建项目时最后一个配置界面，解决办法：在app module的build.gradle的cmake {cppFlags “” }加入 “-frtti” Camera2 报错，原因是安卓从API21才开始引入Camera2，这就是前面建议最低SDK选择API21的原因，如果设备系统版本太低，那就删吧。 5、参考资料 Android Studio 2.2 让你5分钟配置好 OpenCV for Android（java层和native层都可以使用） 使用Android Studio 2.2和Cmake （CMakeLists）让OpenCV 飞起来 我的Android进阶之旅——&gt;Android 关于arm64-v8a、armeabi-v7a、armeabi、x86下的so文件兼容问题 Error: package android.hardware.camera2 does not exist OpenCV Error: Cannot use typeid with -fno-rtti","tags":[{"name":"opencv4android","slug":"opencv4android","permalink":"http://sheng-blog.iego.cn/tags/opencv4android/"}]}]